{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation\n",
    "## Instructions\n",
    "\n",
    "We will train a neural network to draw a curve.\n",
    "The curve takes one input variable, the amount travelled along the curve from 0 to 1, and returns 2 outputs, the 2D coordinates of the position of points on the curve.\n",
    "\n",
    "To help capture the complexity of the curve, we shall use two hidden layers in our network with 6 and 7 neurons respectively.\n",
    "\n",
    "![nn](img/nn_example_graph.png)\n",
    "\n",
    "We will calculate the Jacobian of the cost function, with respect to the weights and biases of the network. It will form part of a stochastic steepest descent algorithm that will train the network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed forward\n",
    "\n",
    "In the following cell, we will define functions to set up our neural network.\n",
    "Namely an activation function, $\\sigma(z)$, it's derivative, $\\sigma'(z)$, a function to initialise weights and biases, and a function that calculates each activation of the network using feed-forward.\n",
    "\n",
    "Recall the feed-forward equations,\n",
    "$$ \\mathbf{a}^{(n)} = \\sigma(\\mathbf{z}^{(n)}) $$\n",
    "$$ \\mathbf{z}^{(n)} = \\mathbf{W}^{(n)}\\mathbf{a}^{(n-1)} + \\mathbf{b}^{(n)} $$\n",
    "\n",
    "In this worksheet we will use the *logistic function* as our activation function, rather than the more familiar $\\tanh$.\n",
    "$$ \\sigma(\\mathbf{z}) = \\frac{1}{1 + \\exp(-\\mathbf{z})} $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
